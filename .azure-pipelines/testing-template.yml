jobs:
- ${{ each gids in parameters.gpu_inds }}:
  - ${{ each config in parameters.configs }}:
    - job:
      displayName: "domain ${{config}} with GPUs ${{gids}}"
      # how long to run the job before automatically cancelling
      timeoutInMinutes: 45
      # how much time to give 'run always even if cancelled tasks' before stopping them
      cancelTimeoutInMinutes: 2

      pool: azure-gpus-spot
      # this need to have installed docker in the base image...
      container:
        # base ML image: mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04
        image: "pytorchlightning/pytorch_lightning:base-cuda-py3.9-torch1.9"
        # image: "pytorch/pytorch:1.8.1-cuda11.0-cudnn8-runtime"
        options: "-it --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=all --shm-size=32g"

      workspace:
        clean: all
      steps:

      - bash: |
          lspci | egrep 'VGA|3D'
          whereis nvidia
          nvidia-smi
          python --version
          pip --version
          pip list
          df -kh /dev/shm
        displayName: 'Image info & NVIDIA'

      - bash: |
          python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu >= 2, f'GPU: {mgpu}'"
        displayName: 'Sanity check'

      - bash: |
          apt-get install libgl1
        displayName: 'Install OpenCV dependencies'
        condition: eq('${{ config }}', 'image_extras')

      - bash: |
          # python -m pip install "pip==20.1"
          if [ "${{config}}" == "image_extras" ]; then pip install '.[image]' icevision effdet; else pip install '.[${{config}}]' torchtext --upgrade; fi
          pip install '.[test]' --upgrade-strategy only-if-needed
          pip list
        displayName: 'Install dependencies'

      - bash: |
          python -c "import torch; print(f'found GPUs: {torch.cuda.device_count()}')"
          python -m coverage run --source flash -m pytest tests/examples/test_scripts.py -v --junitxml=$(Build.StagingDirectory)/test-results.xml --durations=30
        env:
          CUDA_VISIBLE_DEVICES: ${{gids}}
        displayName: 'Testing'

      - bash: |
          python -m coverage report
          python -m coverage xml
          python -m coverage html
          python -m codecov --token=$(CODECOV_TOKEN) --commit=$(Build.SourceVersion) --flags=gpu,pytest --name="GPU-coverage" --env=linux,azure
          ls -l
        displayName: 'Statistics'

      - task: PublishTestResults@2
        displayName: 'Publish test results'
        inputs:
          testResultsFiles: '$(Build.StagingDirectory)/test-results.xml'
          testRunTitle: '$(Agent.OS) - $(Build.DefinitionName) - Python $(python.version)'
        condition: succeededOrFailed()

      - task: PublishCodeCoverageResults@1
        displayName: 'Publish coverage report'
        inputs:
          codeCoverageTool: 'cobertura'
          summaryFileLocation: 'coverage.xml'
          reportDirectory: '$(Build.SourcesDirectory)/htmlcov'
          testRunTitle: '$(Agent.OS) - $(Build.BuildNumber)[$(Agent.JobName)] - Python $(python.version)'
        condition: succeededOrFailed()
